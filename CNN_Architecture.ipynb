{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolved Image (Feature Map):\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Q.No.1>  Implement a basic convolution operation using a filter and a 5x5 image (matrix).\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Define the Image (5x5 matrix)\n",
    "image = np.array([\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [6, 7, 8, 9, 10],\n",
    "    [11, 12, 13, 14, 15],\n",
    "    [16, 17, 18, 19, 20],\n",
    "    [21, 22, 23, 24, 25]\n",
    "])\n",
    "\n",
    "# Step 2: Define the Filter (3x3 kernel)\n",
    "filter_kernel = np.array([\n",
    "    [0, 1, 0],\n",
    "    [1, -4, 1],\n",
    "    [0, 1, 0]\n",
    "])\n",
    "\n",
    "# Step 3: Apply the convolution operation\n",
    "# Create an output matrix for storing results\n",
    "output = np.zeros((image.shape[0] - filter_kernel.shape[0] + 1, image.shape[1] - filter_kernel.shape[1] + 1))\n",
    "\n",
    "# Convolution operation: slide the filter over the image\n",
    "for i in range(output.shape[0]):\n",
    "    for j in range(output.shape[1]):\n",
    "        # Extract the region of interest (ROI)\n",
    "        region = image[i:i+filter_kernel.shape[0], j:j+filter_kernel.shape[1]]\n",
    "        # Perform element-wise multiplication and sum the result\n",
    "        output[i, j] = np.sum(region * filter_kernel)\n",
    "\n",
    "# Step 4: Display the result\n",
    "print(\"Convolved Image (Feature Map):\")\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Argument `output` must have rank (ndim) `target.ndim - 1`. Received: target.shape=(None, 10), output.shape=(None, 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 35\u001b[0m\n\u001b[0;32m     23\u001b[0m model\u001b[38;5;241m=\u001b[39mSequential([\n\u001b[0;32m     24\u001b[0m     Conv2D(\u001b[38;5;241m32\u001b[39m,(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m),activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m,input_shape\u001b[38;5;241m=\u001b[39m(image_size,image_size,\u001b[38;5;241m1\u001b[39m)),\n\u001b[0;32m     25\u001b[0m     MaxPooling2D(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m     Dense(\u001b[38;5;241m10\u001b[39m,activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     29\u001b[0m ])\n\u001b[0;32m     31\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     32\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     33\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 35\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:652\u001b[0m, in \u001b[0;36msparse_categorical_crossentropy\u001b[1;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    647\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument `output` must be at least rank 1. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    648\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    649\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    650\u001b[0m     )\n\u001b[0;32m    651\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n\u001b[1;32m--> 652\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    653\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument `output` must have rank (ndim) `target.ndim - 1`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    654\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    655\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    656\u001b[0m     )\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape, output\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 \u001b[38;5;241m!=\u001b[39m e2:\n",
      "\u001b[1;31mValueError\u001b[0m: Argument `output` must have rank (ndim) `target.ndim - 1`. Received: target.shape=(None, 10), output.shape=(None, 10)"
     ]
    }
   ],
   "source": [
    "#Q.No.2> Implement max pooling on a 4x4 feature map with a 2x2 window.\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import MaxPooling2D,Dense,Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Parameters\n",
    "num_samples = 1000  # Number of samples in the dataset\n",
    "image_size = 28  # Image dimensions (28x28)\n",
    "num_classes = 10  # Number of classes (can be adjusted)\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "\n",
    "# 1. Generate a synthetic dataset \n",
    "X_train = np.random.rand(num_samples, image_size, image_size, 1)\n",
    "y_train = np.random.randint(0, num_classes, num_samples)  # Random integer labels between 0 and num_classes-1\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "\n",
    "model=Sequential([\n",
    "    Conv2D(32,(3,3),activation='relu',input_shape=(image_size,image_size,1)),\n",
    "    MaxPooling2D(3,3),\n",
    "    Flatten(),\n",
    "    Dense(64,activation='relu'),\n",
    "    Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,y_train,epochs=epochs,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 3]\n",
      " [0 2 0]\n",
      " [4 0 6]]\n"
     ]
    }
   ],
   "source": [
    "#Q.No.3> Implement the ReLU activation function on a feature map?\n",
    "import numpy as np\n",
    "\n",
    "# Sample feature map (2D array)\n",
    "feature_map = np.array([[1, -2, 3],\n",
    "                        [-1, 2, -3],\n",
    "                        [4, -5, 6]])\n",
    "\n",
    "# Applying ReLU activation function element-wise\n",
    "relu_feature_map = np.maximum(0, feature_map)\n",
    "\n",
    "print(relu_feature_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3232,  0.0120,  0.2898,  0.0912,  0.1548,  0.1902, -0.1297, -0.0672,\n",
      "         -0.0352, -0.1783],\n",
      "        [-0.1687, -0.0269,  0.1625, -0.0780, -0.0023,  0.1398, -0.0156, -0.0182,\n",
      "          0.0621, -0.0563],\n",
      "        [ 0.2263,  0.0401,  0.0088,  0.2593, -0.0492,  0.1218, -0.1097,  0.0723,\n",
      "         -0.0978,  0.2580],\n",
      "        [ 0.1655,  0.1296,  0.1769, -0.0785,  0.1476,  0.0290, -0.0416, -0.0004,\n",
      "          0.0889, -0.0715]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Q.No.4>  Create a simple CNN model with one convolutional layer and a fully connected layer, using random data?\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the CNN class\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        # Convolutional Layer (1 input channel, 1 output channel, kernel size 3x3)\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3)\n",
    "        \n",
    "        # Fully Connected Layer (input size 26*26 after 3x3 convolution, output size 10)\n",
    "        self.fc1 = nn.Linear(1 * 26 * 26, 10)  # Flattened size after convolution\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass through convolutional layer, then ReLU activation\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        # Flatten the output for the fully connected layer\n",
    "        x = x.view(x.size(0), -1)  # Flattening\n",
    "        \n",
    "        # Pass through the fully connected layer\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleCNN()\n",
    "\n",
    "# Generate random data (batch size 4, 1 channel, 28x28 images)\n",
    "random_data = torch.randn(4, 1, 28, 28)  # Random data with shape (batch_size, channels, height, width)\n",
    "\n",
    "# Forward pass through the model\n",
    "output = model(random_data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 2.4901, Accuracy: 9.90%\n",
      "Epoch [2/5], Loss: 1.8247, Accuracy: 41.80%\n",
      "Epoch [3/5], Loss: 1.3234, Accuracy: 63.40%\n",
      "Epoch [4/5], Loss: 0.8585, Accuracy: 85.00%\n",
      "Epoch [5/5], Loss: 0.5367, Accuracy: 94.30%\n"
     ]
    }
   ],
   "source": [
    "#Q.No.5>  Generate a synthetic dataset using random noise and train a simple CNN model on it.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Create a synthetic dataset with random noise and labels\n",
    "class RandomNoiseDataset(Dataset):\n",
    "    def __init__(self, num_samples, image_size=(1, 28, 28), num_classes=10):\n",
    "        self.num_samples = num_samples\n",
    "        self.image_size = image_size\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Generate random images (noise) and random labels\n",
    "        self.data = torch.randn(num_samples, *image_size)  # Random noise\n",
    "        self.labels = torch.randint(0, num_classes, (num_samples,))  # Random labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# Step 2: Define the CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3)  # 1 input channel, 8 output channels\n",
    "        self.fc1 = nn.Linear(8 * 26 * 26, 10)  # Flattening output from convolution to 10 outputs for classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)  # Apply convolution\n",
    "        x = torch.relu(x)  # ReLU activation\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output\n",
    "        x = self.fc1(x)  # Fully connected layer\n",
    "        return x\n",
    "\n",
    "# Step 3: Set up dataset, model, loss, and optimizer\n",
    "num_samples = 1000  # Number of random images\n",
    "batch_size = 32  # Size of mini-batches\n",
    "num_epochs = 5  # Number of training epochs\n",
    "\n",
    "# Create the dataset and data loader\n",
    "dataset = RandomNoiseDataset(num_samples=num_samples)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleCNN()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Suitable for multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Step 4: Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in dataloader:\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track loss and accuracy\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │           \u001b[38;5;34m224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │            \u001b[38;5;34m90\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">314</span> (1.23 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m314\u001b[0m (1.23 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">314</span> (1.23 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m314\u001b[0m (1.23 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Q.No.6>  Create a simple CNN using Keras with one convolution layer and a max-pooling layer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense,Flatten,Conv2D,MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "model=Sequential([\n",
    "    Conv2D(8,(3,3),activation='relu',input_shape=(32,32,3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,672</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │           \u001b[38;5;34m224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m4,672\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m10\u001b[0m)       │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,122</span> (86.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,122\u001b[0m (86.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,122</span> (86.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,122\u001b[0m (86.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Q.No.7>  Write a code to add a fully connected layer after the convolution and max-pooling layers in a CNN.\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense,Flatten,Conv2D,MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "model=Sequential([\n",
    "    Conv2D(8,(3,3),activation='relu',input_shape=(32,32,3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(64,(3,3),activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dense(64,activation='relu'),\n",
    "    Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1800</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">230,528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │           \u001b[38;5;34m224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1800\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m230,528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">240,426</span> (939.16 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m240,426\u001b[0m (939.16 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">240,042</span> (937.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m240,042\u001b[0m (937.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Q.No.8>  Write a code to add  batch normalization to a simple CNN model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense,Flatten,Conv2D,MaxPooling2D,Dropout,BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "model=Sequential([\n",
    "    Conv2D(8,(3,3),activation='relu',input_shape=(32,32,3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dense(128,activation='softmax'),\n",
    "    BatchNormalization(),\n",
    "    Dense(64,activation='softmax'),\n",
    "    BatchNormalization(),\n",
    "    Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1800</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">230,528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │           \u001b[38;5;34m224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1800\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m230,528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">239,658</span> (936.16 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m239,658\u001b[0m (936.16 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">239,658</span> (936.16 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m239,658\u001b[0m (936.16 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Q.No.9>  Write a code to add dropout regularization to a simple CNN model.\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense,Flatten,Conv2D,MaxPooling2D,Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "model=Sequential([\n",
    "    Conv2D(8,(3,3),activation='relu',input_shape=(32,32,3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dense(128,activation='softmax'),\n",
    "    Dropout(0.2),\n",
    "    Dense(64,activation='softmax'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m770s\u001b[0m 13us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ vgg16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,422,784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ vgg16 (\u001b[38;5;33mFunctional\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │    \u001b[38;5;34m14,714,688\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m6,422,784\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,137,472</span> (80.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,137,472\u001b[0m (80.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,422,784</span> (24.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,422,784\u001b[0m (24.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Q.No.10>  Write a code to print the architecture of the VGG16 model in Keras?\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras import layers, models\n",
    "vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "vgg16_base.trainable = False\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "\n",
    "model.add(vgg16_base)\n",
    "model.add(layers.Flatten())  \n",
    "model.add(layers.Dense(256, activation='relu'))  \n",
    "model.add(layers.Dropout(0.5))  \n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.3650 - loss: 1.7223 - val_accuracy: 0.5744 - val_loss: 1.2085\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5903 - loss: 1.1592 - val_accuracy: 0.6277 - val_loss: 1.0587\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.6509 - loss: 0.9923 - val_accuracy: 0.6541 - val_loss: 0.9920\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.6821 - loss: 0.9114 - val_accuracy: 0.6660 - val_loss: 0.9635\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.7148 - loss: 0.8240 - val_accuracy: 0.6672 - val_loss: 0.9651\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.7366 - loss: 0.7538 - val_accuracy: 0.6737 - val_loss: 0.9511\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7615 - loss: 0.6823 - val_accuracy: 0.6780 - val_loss: 0.9485\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7774 - loss: 0.6328 - val_accuracy: 0.6688 - val_loss: 0.9956\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.7993 - loss: 0.5665 - val_accuracy: 0.6794 - val_loss: 1.0227\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8266 - loss: 0.4932 - val_accuracy: 0.6712 - val_loss: 1.0531\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Q.No.11>  Write a code to plot the accuracy and loss graphs after training a CNN model.\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense,Flatten,Conv2D,MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "(x_train,y_train),(x_test,y_test)=cifar10.load_data()\n",
    "x_train=x_train/255.0\n",
    "x_test=x_test/255.0\n",
    "\n",
    "model=Sequential([\n",
    "    Conv2D(8,(3,3),activation='relu',input_shape=(32,32,3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(64,(3,3),activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dense(64,activation='relu'),\n",
    "    Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))\n",
    "\n",
    "#plotting accuracy and loss during training\n",
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.plot(history.history['accuracy'],label='Training Accuracy')\n",
    "plt.plot(history.history['loss'],label='Training loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ vgg16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,422,784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ vgg16 (\u001b[38;5;33mFunctional\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │    \u001b[38;5;34m14,714,688\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m6,422,784\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,137,472</span> (80.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,137,472\u001b[0m (80.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,422,784</span> (24.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,422,784\u001b[0m (24.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Q.No.12>  Write a code to print the architecture of the ResNet50 model in Keras?\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense,Flatten,Conv2D,MaxPooling2D,GlobalAveragePooling2D\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.applications import ResNet50\n",
    "\n",
    "base_model=ResNet50(weights='imagenet',include_top=False,input_shape=(224,224,3))\n",
    "x=base_model.output\n",
    "x1=GlobalAveragePooling2D()(x)\n",
    "x2=Dense(1024,activation='relu')(x1)\n",
    "prediction=Dense(10,activation='softmax')(x2)\n",
    "\n",
    "model_feat=Model(inputs=base_model.input,outputs=prediction)\n",
    "\n",
    "model_feat.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "[[[[ 59  62  63]\n",
      "   [ 43  46  45]\n",
      "   [ 50  48  43]\n",
      "   ...\n",
      "   [158 132 108]\n",
      "   [152 125 102]\n",
      "   [148 124 103]]\n",
      "\n",
      "  [[ 16  20  20]\n",
      "   [  0   0   0]\n",
      "   [ 18   8   0]\n",
      "   ...\n",
      "   [123  88  55]\n",
      "   [119  83  50]\n",
      "   [122  87  57]]\n",
      "\n",
      "  [[ 25  24  21]\n",
      "   [ 16   7   0]\n",
      "   [ 49  27   8]\n",
      "   ...\n",
      "   [118  84  50]\n",
      "   [120  84  50]\n",
      "   [109  73  42]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[208 170  96]\n",
      "   [201 153  34]\n",
      "   [198 161  26]\n",
      "   ...\n",
      "   [160 133  70]\n",
      "   [ 56  31   7]\n",
      "   [ 53  34  20]]\n",
      "\n",
      "  [[180 139  96]\n",
      "   [173 123  42]\n",
      "   [186 144  30]\n",
      "   ...\n",
      "   [184 148  94]\n",
      "   [ 97  62  34]\n",
      "   [ 83  53  34]]\n",
      "\n",
      "  [[177 144 116]\n",
      "   [168 129  94]\n",
      "   [179 142  87]\n",
      "   ...\n",
      "   [216 184 140]\n",
      "   [151 118  84]\n",
      "   [123  92  72]]]\n",
      "\n",
      "\n",
      " [[[154 177 187]\n",
      "   [126 137 136]\n",
      "   [105 104  95]\n",
      "   ...\n",
      "   [ 91  95  71]\n",
      "   [ 87  90  71]\n",
      "   [ 79  81  70]]\n",
      "\n",
      "  [[140 160 169]\n",
      "   [145 153 154]\n",
      "   [125 125 118]\n",
      "   ...\n",
      "   [ 96  99  78]\n",
      "   [ 77  80  62]\n",
      "   [ 71  73  61]]\n",
      "\n",
      "  [[140 155 164]\n",
      "   [139 146 149]\n",
      "   [115 115 112]\n",
      "   ...\n",
      "   [ 79  82  64]\n",
      "   [ 68  70  55]\n",
      "   [ 67  69  55]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[175 167 166]\n",
      "   [156 154 160]\n",
      "   [154 160 170]\n",
      "   ...\n",
      "   [ 42  34  36]\n",
      "   [ 61  53  57]\n",
      "   [ 93  83  91]]\n",
      "\n",
      "  [[165 154 128]\n",
      "   [156 152 130]\n",
      "   [159 161 142]\n",
      "   ...\n",
      "   [103  93  96]\n",
      "   [123 114 120]\n",
      "   [131 121 131]]\n",
      "\n",
      "  [[163 148 120]\n",
      "   [158 148 122]\n",
      "   [163 156 133]\n",
      "   ...\n",
      "   [143 133 139]\n",
      "   [143 134 142]\n",
      "   [143 133 144]]]\n",
      "\n",
      "\n",
      " [[[255 255 255]\n",
      "   [253 253 253]\n",
      "   [253 253 253]\n",
      "   ...\n",
      "   [253 253 253]\n",
      "   [253 253 253]\n",
      "   [253 253 253]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [254 254 254]\n",
      "   [254 254 254]\n",
      "   ...\n",
      "   [254 254 254]\n",
      "   [254 254 254]\n",
      "   [254 254 254]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[113 120 112]\n",
      "   [111 118 111]\n",
      "   [105 112 106]\n",
      "   ...\n",
      "   [ 72  81  80]\n",
      "   [ 72  80  79]\n",
      "   [ 72  80  79]]\n",
      "\n",
      "  [[111 118 110]\n",
      "   [104 111 104]\n",
      "   [ 99 106  98]\n",
      "   ...\n",
      "   [ 68  75  73]\n",
      "   [ 70  76  75]\n",
      "   [ 78  84  82]]\n",
      "\n",
      "  [[106 113 105]\n",
      "   [ 99 106  98]\n",
      "   [ 95 102  94]\n",
      "   ...\n",
      "   [ 78  85  83]\n",
      "   [ 79  85  83]\n",
      "   [ 80  86  84]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 35 178 235]\n",
      "   [ 40 176 239]\n",
      "   [ 42 176 241]\n",
      "   ...\n",
      "   [ 99 177 219]\n",
      "   [ 79 147 197]\n",
      "   [ 89 148 189]]\n",
      "\n",
      "  [[ 57 182 234]\n",
      "   [ 44 184 250]\n",
      "   [ 50 183 240]\n",
      "   ...\n",
      "   [156 182 200]\n",
      "   [141 177 206]\n",
      "   [116 149 175]]\n",
      "\n",
      "  [[ 98 197 237]\n",
      "   [ 64 189 252]\n",
      "   [ 69 192 245]\n",
      "   ...\n",
      "   [188 195 206]\n",
      "   [119 135 147]\n",
      "   [ 61  79  90]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 73  79  77]\n",
      "   [ 53  63  68]\n",
      "   [ 54  68  80]\n",
      "   ...\n",
      "   [ 17  40  64]\n",
      "   [ 21  36  51]\n",
      "   [ 33  48  49]]\n",
      "\n",
      "  [[ 61  68  75]\n",
      "   [ 55  70  86]\n",
      "   [ 57  79 103]\n",
      "   ...\n",
      "   [ 24  48  72]\n",
      "   [ 17  35  53]\n",
      "   [  7  23  32]]\n",
      "\n",
      "  [[ 44  56  73]\n",
      "   [ 46  66  88]\n",
      "   [ 49  77 105]\n",
      "   ...\n",
      "   [ 27  52  77]\n",
      "   [ 21  43  66]\n",
      "   [ 12  31  50]]]\n",
      "\n",
      "\n",
      " [[[189 211 240]\n",
      "   [186 208 236]\n",
      "   [185 207 235]\n",
      "   ...\n",
      "   [175 195 224]\n",
      "   [172 194 222]\n",
      "   [169 194 220]]\n",
      "\n",
      "  [[194 210 239]\n",
      "   [191 207 236]\n",
      "   [190 206 235]\n",
      "   ...\n",
      "   [173 192 220]\n",
      "   [171 191 218]\n",
      "   [167 190 216]]\n",
      "\n",
      "  [[208 219 244]\n",
      "   [205 216 240]\n",
      "   [204 215 239]\n",
      "   ...\n",
      "   [175 191 217]\n",
      "   [172 190 216]\n",
      "   [169 191 215]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[207 199 181]\n",
      "   [203 195 175]\n",
      "   [203 196 173]\n",
      "   ...\n",
      "   [135 132 127]\n",
      "   [162 158 150]\n",
      "   [168 163 151]]\n",
      "\n",
      "  [[198 190 170]\n",
      "   [189 181 159]\n",
      "   [180 172 147]\n",
      "   ...\n",
      "   [178 171 160]\n",
      "   [175 169 156]\n",
      "   [175 169 154]]\n",
      "\n",
      "  [[198 189 173]\n",
      "   [189 181 162]\n",
      "   [178 170 149]\n",
      "   ...\n",
      "   [195 184 169]\n",
      "   [196 189 171]\n",
      "   [195 190 171]]]\n",
      "\n",
      "\n",
      " [[[229 229 239]\n",
      "   [236 237 247]\n",
      "   [234 236 247]\n",
      "   ...\n",
      "   [217 219 233]\n",
      "   [221 223 234]\n",
      "   [222 223 233]]\n",
      "\n",
      "  [[222 221 229]\n",
      "   [239 239 249]\n",
      "   [233 234 246]\n",
      "   ...\n",
      "   [223 223 236]\n",
      "   [227 228 238]\n",
      "   [210 211 220]]\n",
      "\n",
      "  [[213 206 211]\n",
      "   [234 232 239]\n",
      "   [231 233 244]\n",
      "   ...\n",
      "   [220 220 232]\n",
      "   [220 219 232]\n",
      "   [202 203 215]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[150 143 135]\n",
      "   [140 135 127]\n",
      "   [132 127 120]\n",
      "   ...\n",
      "   [224 222 218]\n",
      "   [230 228 225]\n",
      "   [241 241 238]]\n",
      "\n",
      "  [[137 132 126]\n",
      "   [130 127 120]\n",
      "   [125 121 115]\n",
      "   ...\n",
      "   [181 180 178]\n",
      "   [202 201 198]\n",
      "   [212 211 207]]\n",
      "\n",
      "  [[122 119 114]\n",
      "   [118 116 110]\n",
      "   [120 116 111]\n",
      "   ...\n",
      "   [179 177 173]\n",
      "   [164 164 162]\n",
      "   [163 163 161]]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3419 - loss: 1.8586 - val_accuracy: 0.4870 - val_loss: 1.4526\n",
      "Epoch 2/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5097 - loss: 1.4091 - val_accuracy: 0.5244 - val_loss: 1.3605\n",
      "Epoch 3/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5432 - loss: 1.3175 - val_accuracy: 0.5390 - val_loss: 1.3152\n",
      "Epoch 4/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5648 - loss: 1.2620 - val_accuracy: 0.5449 - val_loss: 1.2895\n",
      "Epoch 5/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5799 - loss: 1.2181 - val_accuracy: 0.5556 - val_loss: 1.2610\n",
      "Epoch 6/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5883 - loss: 1.1878 - val_accuracy: 0.5647 - val_loss: 1.2368\n",
      "Epoch 7/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5950 - loss: 1.1695 - val_accuracy: 0.5538 - val_loss: 1.2556\n",
      "Epoch 8/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5979 - loss: 1.1500 - val_accuracy: 0.5697 - val_loss: 1.2362\n",
      "Epoch 9/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6108 - loss: 1.1309 - val_accuracy: 0.5747 - val_loss: 1.2243\n",
      "Epoch 10/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6083 - loss: 1.1354 - val_accuracy: 0.5649 - val_loss: 1.2424\n",
      "Epoch 1:\n",
      "Training Loss: 1.6676\n",
      "Training Accuracy: 0.4182\n",
      "Epoch 2:\n",
      "Training Loss: 1.3904\n",
      "Training Accuracy: 0.5170\n",
      "Epoch 3:\n",
      "Training Loss: 1.3061\n",
      "Training Accuracy: 0.5486\n",
      "Epoch 4:\n",
      "Training Loss: 1.2573\n",
      "Training Accuracy: 0.5657\n",
      "Epoch 5:\n",
      "Training Loss: 1.2179\n",
      "Training Accuracy: 0.5788\n",
      "Epoch 6:\n",
      "Training Loss: 1.1925\n",
      "Training Accuracy: 0.5869\n",
      "Epoch 7:\n",
      "Training Loss: 1.1721\n",
      "Training Accuracy: 0.5939\n",
      "Epoch 8:\n",
      "Training Loss: 1.1568\n",
      "Training Accuracy: 0.5996\n",
      "Epoch 9:\n",
      "Training Loss: 1.1436\n",
      "Training Accuracy: 0.6036\n",
      "Epoch 10:\n",
      "Training Loss: 1.1346\n",
      "Training Accuracy: 0.6077\n"
     ]
    }
   ],
   "source": [
    "#Q.No.13>  Write a code to train a basic CNN model and print the training loss and accuracy after each epoch?\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense,Flatten,Conv2D,MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "\n",
    "(x_train,y_train),(x_test,y_test)=cifar10.load_data()\n",
    "print(x_train.shape)\n",
    "print(x_train)\n",
    "x_train=x_train/255.0\n",
    "x_test=x_test/255.\n",
    "\n",
    "model=Sequential([\n",
    "    Conv2D(8,(3,3),activation='relu',input_shape=(32,32,3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=64, validation_data=(x_test, y_test))\n",
    "\n",
    "for epoch in range(10):\n",
    "    print(f\"Epoch {epoch+1}:\")\n",
    "    print(f\"Training Loss: {history.history['loss'][epoch]:.4f}\")\n",
    "    print(f\"Training Accuracy: {history.history['accuracy'][epoch]:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
